{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN (d-M-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "train_data=np.loadtxt('hw4_nnet_train.txt')\n",
    "test_data=np.loadtxt('hw4_nnet_test.txt')\n",
    "\n",
    "train_X=train_data[:,0:-1]\n",
    "train_y=train_data[:,-1]\n",
    "test_X=test_data[:,0:-1]\n",
    "test_y=test_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self,M,r,eta,T):  # M是隐藏层神经元数目，r是theta随机化的范围，eta是学习率,T表示总共训练T个数据\n",
    "        self.M=M\n",
    "        self.r=r\n",
    "        self.eta=eta\n",
    "        self.T=T\n",
    "        \n",
    "    # tanh的导数函数\n",
    "    def dertanh(self,s):\n",
    "        return 1-np.tanh(s)**2\n",
    "    \n",
    "    # 初始化theta函数\n",
    "    def inittheta(self,d):\n",
    "        theta1 = np.random.uniform(-self.r, self.r, (d, self.M))\n",
    "        theta2 = np.random.uniform(-self.r, self.r, (self.M+1, 1))\n",
    "        return theta1,theta2\n",
    "    \n",
    "    # 神经网络函数---BP更新参数 （前向+反向）\n",
    "    def updateTheta(self,train_X, train_y):\n",
    "        row, col = train_X.shape           #col这里为2，表示2个特征值\n",
    "        theta1,theta2=self.inittheta(col)\n",
    "        for i in range(self.T):\n",
    "            # 前向传播\n",
    "            randpos = np.random.randint(0, row)\n",
    "            xone = train_X[randpos: randpos+1, :]               #一行两列，随机取出一个数据训练\n",
    "            yone = train_y[randpos]\n",
    "            s1 = xone.dot(theta1)\n",
    "            x1 = np.tanh(s1)\n",
    "            x1 = np.c_[np.ones((1, 1)), x1]      # np.c_是行连接两个矩阵,np.r_是列连接两个矩阵\n",
    "            s2 = x1.dot(theta2)\n",
    "            x2 = np.tanh(s2)[0][0]\n",
    "            delta2 = -2*(yone-x2)\n",
    "            delta1 = delta2*theta2[1:, :].T*self.dertanh(s1)\n",
    "            theta2 -= self.eta*x1.T*delta2\n",
    "            theta1 -= self.eta*xone.T.dot(delta1)\n",
    "        return theta1,theta2\n",
    "    \n",
    "    # 误差衡量函数\n",
    "    def errfun(self,test_X, test_y,theta):\n",
    "        row, col = test_X.shape\n",
    "        l = len(theta)          #这里l=2\n",
    "        x = test_X\n",
    "        for i in range(l-1):\n",
    "            x = np.c_[np.ones((row, 1)), np.tanh(x.dot(theta[i]))]\n",
    "        x2 = np.tanh(x.dot(theta[l-1]))\n",
    "        Yhat = x2\n",
    "        Yhat[Yhat>=0] = 1\n",
    "        Yhat[Yhat<0] = -1\n",
    "        Yhat=Yhat.reshape(Yhat.shape[0],)             #把dim从原来的（M，1）变成 （M，）\n",
    "        return np.sum(Yhat != test_y)/row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completion rate:  0 / 3\n",
      "completion rate:  5 / 3\n",
      "completion rate:  10 / 3\n",
      "completion rate:  15 / 3\n",
      "completion rate:  20 / 3\n",
      "completion rate:  25 / 3\n",
      "[4.796      4.9        4.764      4.61333333 4.756     ]\n"
     ]
    }
   ],
   "source": [
    "# Q11，比较中间隐藏层不同神经元个数对结果的影响\n",
    "M = [1, 6, 11, 16, 21]\n",
    "eout = np.zeros((len(M),))\n",
    "for i in range(3):\n",
    "    if (i+1)%5 == 0:\n",
    "        print(\"completion rate: \",i+1,\"/ 3\")\n",
    "    for j in range(len(M)):\n",
    "        network=CNN(M[j],0.1,0.1,50000)\n",
    "        theta1,theta2=network.updateTheta(train_X,train_y)\n",
    "        theta=[theta1,theta2]\n",
    "        eout[j] += network.errfun(test_X, test_y,theta)\n",
    "print(eout/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completion rate:  5 / 20\n",
      "completion rate:  10 / 20\n",
      "completion rate:  15 / 20\n",
      "completion rate:  20 / 20\n",
      "[0.4888 0.5008 0.4418 0.4234 0.4526]\n"
     ]
    }
   ],
   "source": [
    "# Q12，比较theta随机化的范围对结果的影响\n",
    "r = [0, 0.1, 10, 100, 1000]\n",
    "eout = np.zeros((len(r),))\n",
    "for i in range(50):\n",
    "    if (i+1)%5 == 0:\n",
    "        print(\"completion rate: \",i+1,\"/ 50\")\n",
    "    for j in range(len(r)):\n",
    "        network=CNN(3,r[j],0.1,50000)\n",
    "        theta=network.updateTheta(train_X,train_y)\n",
    "        eout[j] += network.errfun(test_X, test_y, theta)\n",
    "print(eout / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completion rate:  5 / 50\n",
      "completion rate:  10 / 50\n",
      "completion rate:  15 / 50\n",
      "completion rate:  20 / 50\n",
      "completion rate:  25 / 50\n",
      "completion rate:  30 / 50\n",
      "completion rate:  35 / 50\n",
      "completion rate:  40 / 50\n",
      "completion rate:  45 / 50\n",
      "completion rate:  50 / 50\n",
      "[0.62256 0.49632 0.49024 0.45712 0.45424]\n"
     ]
    }
   ],
   "source": [
    "# Q13 比较学习率对结果的影响\n",
    "eta = [0.001, 0.01, 0.1, 1, 10]\n",
    "eout = np.zeros((len(eta),))\n",
    "for i in range(50):\n",
    "    if (i+1)%5 == 0:\n",
    "        print(\"completion rate: \",i+1,\"/ 50\")\n",
    "    for j in range(len(eta)):\n",
    "        network=CNN(3,0.1,eta[j],50000)\n",
    "        theta=network.updateTheta(train_X,train_y)\n",
    "        eout[j] += network.errfun(test_X, test_y, theta)\n",
    "print(eout / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#扩展网络，将其变为d−8−3−1型的神经网络，其他与之前网络均类似\n",
    "# 多层神经网络\n",
    "def nnetwork2hidden(X, Y, d1, d2, T):\n",
    "    row, col = X.shape\n",
    "    theta1 = np.random.uniform(-0.1, 0.1, (col, d1))\n",
    "    theta2 = np.random.uniform(-0.1, 0.1, (d1+1, d2))\n",
    "    theta3 = np.random.uniform(-0.1, 0.1, (d2+1, 1))\n",
    "    for i in range(T):\n",
    "        # 前向传播\n",
    "        randpos = np.random.randint(0, row)\n",
    "        xone = X[randpos: randpos+1, :]\n",
    "        yone = Y[randpos]\n",
    "        s1 = xone.dot(theta1)\n",
    "        x1 = np.tanh(s1)\n",
    "        x1 = np.c_[np.ones((1, 1)), x1]\n",
    "        s2 = x1.dot(theta2)\n",
    "        x2 = np.tanh(s2)\n",
    "        x2 = np.c_[np.ones((1, 1)), x2]\n",
    "        s3 = x2.dot(theta3)\n",
    "        x3 = np.tanh(s3)[0][0]\n",
    "        delta3 = -2*(yone-x3)\n",
    "        delta2 = delta3*theta3[1:, :].T*dertanh(s2)\n",
    "        delta1 = delta2.dot(theta2[1:, :].T)*dertanh(s1)\n",
    "        theta3 -= 0.01*x2.T*delta3\n",
    "        theta2 -= 0.01*x1.T*delta2\n",
    "        theta1 -= 0.01*xone.T.dot(delta1)\n",
    "    return theta1, theta2, theta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14,设置r=0.1,η=0.01，看看该多层神经网络怎么样\n",
    "eout = 0\n",
    "for i in ran，看看该多层神经网络怎么样ge(50):\n",
    "    theta1, theta2, theta3 = nnetwork2hidden(X, Y, 8, 3, 50000)\n",
    "    theta = [theta1, theta2, theta3]\n",
    "    eout += errfun(Xtest, Ytest, theta)\n",
    "print(eout/50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
