{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CART\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART(object):\n",
    "    def __init__(self, x, y, prune=False):\n",
    "        self.x = x \n",
    "        self.y = y \n",
    "        # print('build cart...')\n",
    "        self.branches = self.buildTree(x,y,prune)\n",
    "\n",
    "    def sign(self,v):\n",
    "        if v < 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def buildTree(self,x,y,prune=False):\n",
    "        branches = []\n",
    "        if prune:  #只有一层分支\n",
    "            branch, left, right = self.branchStump(x,y)\n",
    "            branches.append(branch)\n",
    "            if sum(left[1]) >= 0:           #表示对left数据集的y值求和\n",
    "                branches.append([1])\n",
    "            else:\n",
    "                branches.append([-1])\n",
    "            if sum(right[1]) >= 0:\n",
    "                branches.append([1])\n",
    "            else:\n",
    "                branches.append([-1])\n",
    "            return branches\n",
    "        else:    #fully grown\n",
    "            if abs(sum(y)) == len(y):      #二叉决策树终止条件：当前各个分支下包含的所有样本yn都是同类的\n",
    "                branches.append(y[0])\n",
    "                return branches \n",
    "            else:\n",
    "                branch, left, right = self.branchStump(x,y)           #二叉决策树前序排列\n",
    "                branches.append(branch)    \n",
    "                branches.append(self.buildTree(left[0],left[1]))\n",
    "                branches.append(self.buildTree(right[0],right[1]))\n",
    "                return branches \n",
    "            \n",
    "    def branchStump(self, x, y):        #运用desicion stump方法对x和y找到分类出子树的最佳方法！\n",
    "        # print('13. branch tree once...')\n",
    "        dimensions = len(x[0])             #这里dimensions为2，相当于特征数\n",
    "        best_s = True\n",
    "        best_theta = 0\n",
    "        best_dim = 0\n",
    "        best_gini = 100\n",
    "        for dim in range(dimensions):    \n",
    "            thetas = np.sort(x[:,dim]) #1/ 每次只选出某一个特征dim用来做decision stump，并且依据该特征对数据集sort。\n",
    "                                       #2/ 对每个特征，不知道把数据集分到哪一个子分支依据的界限theta是多少，又要每次选出一个theta实验\n",
    "            ss = [True,False] #3/ 不知道x的该特征是正增益还是负增益。所以s为正遍历一遍，为负遍历一遍\n",
    "            for i,theta in enumerate(thetas):\n",
    "                if i > 0:\n",
    "                    theta = (theta+thetas[i-1])/2 #取每个分割段的中间作为theta\n",
    "                else:\n",
    "                    theta = theta/2     #考虑i=0的特殊情况\n",
    "\n",
    "                for s in ss:\n",
    "                    gini = self.computeDivideGini(x,y,s,theta,dim) \n",
    "                    if gini < best_gini:\n",
    "                        best_gini = gini \n",
    "                        best_s = s\n",
    "                        best_theta = theta\n",
    "                        best_dim = dim\n",
    "        branch = [best_s,best_theta,best_dim]           #结果：得到了最适合的s，theta和dim！！！，最适合的依据是基尼系数最小\n",
    "        left,right = self.divideData(x,y,best_s,best_theta,best_dim)     #得到了最适合的左右子树\n",
    "        return branch,left,right \n",
    "    \n",
    "    def hFunc(self, x, s, theta):       #比较x和theta的大小      #s表示方向，可以为true，可以为false\n",
    "        if s:\n",
    "            return self.sign(x-theta)            #表示正方向\n",
    "        else:\n",
    "            return -self.sign(x-theta)\n",
    "    \n",
    "    def divideData(self,x,y,s,theta,dim):     #依据theta这个分割线来具体划分数据集成为两个子数据集\n",
    "        left_x = []\n",
    "        left_y = []\n",
    "        right_x = []\n",
    "        right_y = []\n",
    "        for i in range(len(y)):\n",
    "            if self.hFunc(x[i][dim],s,theta) == -1:              #表示在s方向上x[i][dim]大于theta\n",
    "                left_x.append(x[i])\n",
    "                left_y.append(y[i])\n",
    "            else:\n",
    "                right_x.append(x[i])\n",
    "                right_y.append(y[i])\n",
    "        \n",
    "        # print('left data:',len(left_y), 'right data:',len(right_y))\n",
    "        # 注意：下面这种列表list的拼接方法，如a=[np.array(left_x),np.array(left_y)]表示得到了一个长度为2的数组a，\n",
    "        # a[0]表示left_x，a[1]表示left_y,则a[0][0][0]表示lef_x的第1个元素的第1个特征值\n",
    "        return [np.array(left_x),np.array(left_y)],[np.array(right_x),np.array(right_y)]\n",
    "\n",
    "    def computeDivideGini(self,x,y,s,theta,dim):    #依据theta这个分割线得到对应的两个子数据集\n",
    "        left,right = self.divideData(x,y,s,theta,dim)\n",
    "        left_gini = self.computeGini(left[0],left[1])\n",
    "        right_gini = self.computeGini(right[0],right[1])\n",
    "        return len(left[1])*left_gini+len(right[1])*right_gini\n",
    "\n",
    "    def computeGini(self,x,y):        #计算基尼指数\n",
    "        sums = sum(y)             \n",
    "        lens = len(y)             \n",
    "        if lens == 0:\n",
    "            return 0\n",
    "        pos_num = (sums+lens)/2                 #标签为正的y个数\n",
    "        neg_num = lens-pos_num                  #标签为负的y个数\n",
    "        return 1-(pos_num/lens)*(pos_num/lens)-(neg_num/lens)*(neg_num/lens)\n",
    "\n",
    "    def fit(self,x,branch):             #这里x表示单个数据\n",
    "        if len(branch) == 3:            #父亲+左子树+右子树的结构\n",
    "            dim = branch[0][2]          #dim为父亲的最佳dim\n",
    "            y = self.hFunc(x[dim],branch[0][0],branch[0][1])\n",
    "            if y == -1:\n",
    "                return self.fit(x,branch[1])\n",
    "            else:\n",
    "                return self.fit(x,branch[2])\n",
    "        else:   #当最后长度不为3了，表示已经到叶子了，则取出该叶子的值\n",
    "            return branch[0]    \n",
    "\n",
    "    def predict(self,x):\n",
    "        res = []\n",
    "        for i in range(len(x)):\n",
    "            res.append(self.fit(x[i],self.branches))\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "class RandomForest(object):\n",
    "    \"\"\"docstring for RandomForest\"\"\"         # T表示有多少棵树\n",
    "    def __init__(self, x, y, T, prune=False):\n",
    "         self.x = x\n",
    "         self.y = y\n",
    "         self.T = T \n",
    "         self.trees = self.buildRF(x,y,T,prune)         #所有的树构成的列表\n",
    "\n",
    "    def boostrap(self,x,y,N):         #boostrap:对N个数重新排序，创建新数据集\n",
    "        indexs = [random.randint(0,N) for _ in range(N)]\n",
    "        return x[indexs], y[indexs]\n",
    "\n",
    "    def buildRF(self,x,y,T,prune):\n",
    "        trees = []\n",
    "        for i in range(T):\n",
    "            tx, ty = self.boostrap(x,y,len(y)-1)\n",
    "            trees.append(CART(tx,ty,prune))\n",
    "        return trees \n",
    "\n",
    "    def fit(self,x):         #这里的x是一个数据\n",
    "        res = []\n",
    "        for i in range(self.T):\n",
    "            res.append(self.trees[i].fit(x,self.trees[i].branches))\n",
    "        if sum(res) >= 0:             #所有数的fit的平均\n",
    "            return 1\n",
    "        else:\n",
    "            return -1 \n",
    "\n",
    "    def predict(self,x):\n",
    "        res = []\n",
    "        for i in range(len(x)):\n",
    "            res.append(self.fit(x[i]))\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data...\n",
      "14. E_in: 0.0\n",
      "15. E_out: 0.126\n",
      "random forest: 0 e_in: 0.0 e_out: 0.07599999999999996\n",
      "random forest: 1 e_in: 0.0 e_out: 0.06999999999999995\n",
      "random forest: 2 e_in: 0.0 e_out: 0.07499999999999996\n",
      "random forest: 3 e_in: 0.0 e_out: 0.07299999999999995\n",
      "random forest: 4 e_in: 0.0 e_out: 0.07299999999999995\n",
      "random forest: 5 e_in: 0.0 e_out: 0.07199999999999995\n",
      "random forest: 6 e_in: 0.0 e_out: 0.07699999999999996\n",
      "random forest: 7 e_in: 0.0 e_out: 0.07199999999999995\n",
      "random forest: 8 e_in: 0.0 e_out: 0.06999999999999995\n",
      "random forest: 9 e_in: 0.0 e_out: 0.07099999999999995\n",
      "16. E_g_in: 0.053343333333333874\n",
      "17. E_in: 0.0\n",
      "18. E_out: 0.07289999999999995\n",
      "pruned random forest: 0 e_in: 0.10999999999999999 e_out: 0.15100000000000002\n",
      "pruned random forest: 1 e_in: 0.08999999999999997 e_out: 0.15100000000000002\n",
      "pruned random forest: 2 e_in: 0.12 e_out: 0.14800000000000002\n",
      "pruned random forest: 3 e_in: 0.12 e_out: 0.15900000000000003\n",
      "pruned random forest: 4 e_in: 0.09999999999999998 e_out: 0.15100000000000002\n",
      "pruned random forest: 5 e_in: 0.12 e_out: 0.15500000000000003\n",
      "pruned random forest: 6 e_in: 0.07999999999999996 e_out: 0.14800000000000002\n",
      "pruned random forest: 7 e_in: 0.09999999999999998 e_out: 0.14500000000000002\n",
      "pruned random forest: 8 e_in: 0.09999999999999998 e_out: 0.14500000000000002\n",
      "pruned random forest: 9 e_in: 0.08999999999999997 e_out: 0.14400000000000002\n",
      "19. E_in: 0.10299999999999998\n",
      "20. E_out: 0.14970000000000003\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('load data...')\n",
    "    \n",
    "    train_data=np.loadtxt('train_data.txt')\n",
    "    test_data=np.loadtxt('test_data.txt')\n",
    "    train_x=train_data[:,0:2]\n",
    "    train_y=train_data[:,2]\n",
    "    test_x=test_data[:,0:2]\n",
    "    test_y=test_data[:,2]    \n",
    "\n",
    "    cart = CART(train_x,train_y)\n",
    "    \n",
    "    train_predict = cart.predict(train_x)\n",
    "    E_in = 1-sum(train_predict==train_y)/len(train_y)\n",
    "    print('14. E_in:',E_in)\n",
    "\n",
    "    predicted = cart.predict(test_x)\n",
    "    print('15. E_out:',1-sum(predicted==test_y)/len(test_y))\n",
    "    \n",
    "    times = 10\n",
    "    E_in = 0\n",
    "    E_out = 0\n",
    "    E_g_in = 0\n",
    "    T = 300\n",
    "    for i in range(times):          #随机10次，做10个随机森林，其结果会随着boostrap随机生成的训练集不同而不同\n",
    "        rf = RandomForest(train_x,train_y,T)\n",
    "\n",
    "        for tree in rf.trees:\n",
    "            train_predict = tree.predict(train_x)\n",
    "            g_in = 1-sum(train_predict==train_y)/len(train_y)\n",
    "            E_g_in += g_in                       #这是对300棵树*10==3000棵树分别做预测的训练误差的和\n",
    "\n",
    "        train_predict = rf.predict(train_x)\n",
    "        e_in = 1-sum(train_predict==train_y)/len(train_y)\n",
    "        E_in += e_in                #这是随机森林（1个随机森林（300棵树）*10）的训练误差\n",
    "\n",
    "        predicted = rf.predict(test_x)\n",
    "        e_out = 1-sum(predicted==test_y)/len(test_y)\n",
    "        E_out += e_out              #这是随机森林（1个随机森林（300棵树）*10）的验证误差\n",
    "        print('random forest:',i,'e_in:',e_in,'e_out:',e_out)\n",
    "\n",
    "\n",
    "    print('16. E_g_in:', E_g_in/T/times)\n",
    "    print('17. E_in:', E_in/times)\n",
    "    print('18. E_out:', E_out/times)\n",
    "\n",
    "\n",
    "    E_in = 0\n",
    "    E_out = 0\n",
    "    for i in range(times):\n",
    "        rf = RandomForest(train_x,train_y,T,True)\n",
    "\n",
    "        train_predict = rf.predict(train_x)\n",
    "        e_in = 1-sum(train_predict==train_y)/len(train_y)\n",
    "        E_in += e_in\n",
    "\n",
    "        predicted = rf.predict(test_x)\n",
    "        e_out = 1-sum(predicted==test_y)/len(test_y)\n",
    "        E_out += e_out\n",
    "        print('pruned random forest:',i,'e_in:',e_in,'e_out:',e_out)\n",
    "\n",
    "    print('19. E_in:', E_in/times)\n",
    "    print('20. E_out:', E_out/times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
